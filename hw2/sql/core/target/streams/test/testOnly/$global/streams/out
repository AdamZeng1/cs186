[0m[[0mdebug[0m] [0mForking tests - parallelism = false[0m
[0m[[0mdebug[0m] [0mCreate a single-thread test executor[0m
[0m[[0mdebug[0m] [0mRunner for sbt.FrameworkWrapper produced 0 initial tasks for 0 tests.[0m
[0m[[0mdebug[0m] [0mRunner for org.scalatest.tools.Framework produced 4 initial tasks for 4 tests.[0m
[0m[[0mdebug[0m] [0m  Running TaskDef(org.apache.spark.sql.execution.DiskPartitionSuite, sbt.ForkMain$SubclassFingerscan@1d34ec53, false, [SuiteSelector])[0m
[0m[[0minfo[0m] [0m[32mDiskPartitionSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- disk partition (1 second, 672 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- close input (2 milliseconds)[0m[0m
[0m[[0mdebug[0m] [0m    Produced 0 nested tasks and 2 events.[0m
[0m[[0mdebug[0m] [0m  Running TaskDef(org.apache.spark.sql.execution.DiskHashedRelationSuite, sbt.ForkMain$SubclassFingerscan@62c40aa9, false, [SuiteSelector])[0m
[0m[[0minfo[0m] [0m[32mDiskHashedRelationSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- values are in correct partition (50 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- empty input (30 milliseconds)[0m[0m
[0m[[0mdebug[0m] [0m    Produced 0 nested tasks and 2 events.[0m
[0m[[0mdebug[0m] [0m  Running TaskDef(org.apache.spark.sql.execution.CS186UtilsSuite, sbt.ForkMain$SubclassFingerscan@7849c992, false, [SuiteSelector])[0m
[0m[[0minfo[0m] [0m[32mCS186UtilsSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- caching iterator (210 milliseconds)[0m[0m
[0m[[0minfo[0m] [0m[32m- sequence with 1 UDF (1 millisecond)[0m[0m
[0m[[0mdebug[0m] [0m    Produced 0 nested tasks and 2 events.[0m
[0m[[0mdebug[0m] [0m  Running TaskDef(org.apache.spark.sql.execution.ProjectSuite, sbt.ForkMain$SubclassFingerscan@3d5cb8f5, false, [SuiteSelector])[0m
[0m[[0minfo[0m] [0m[32mProjectSuite:[0m[0m
[0m[[0minfo[0m] [0m[32m- PartitionProject (3 seconds, 414 milliseconds)[0m[0m
[0m[[0mdebug[0m] [0m    Produced 0 nested tasks and 1 events.[0m
[0m[[0mdebug[0m] [0mRunner for sbt.FrameworkWrapper produced 0 initial tasks for 0 tests.[0m
[0m[[0mdebug[0m] [0mSummary for ScalaCheck not available.[0m
[0m[[0minfo[0m] [0mScalaTest[0m
[0m[[0minfo[0m] [0m[36mRun completed in 10 seconds, 133 milliseconds.[0m[0m
[0m[[0minfo[0m] [0m[36mTotal number of tests run: 7[0m[0m
[0m[[0minfo[0m] [0m[36mSuites: completed 4, aborted 0[0m[0m
[0m[[0minfo[0m] [0m[36mTests: succeeded 7, failed 0, canceled 0, ignored 0, pending 0[0m[0m
[0m[[0minfo[0m] [0m[32mAll tests passed.[0m[0m
[0m[[0mdebug[0m] [0mSummary for JUnit not available.[0m
[0m[[0minfo[0m] [0mPassed: Total 7, Failed 0, Errors 0, Passed 7[0m
[0m[[0mdebug[0m] [0mPassed tests:[0m
[0m[[0mdebug[0m] [0m	org.apache.spark.sql.execution.ProjectSuite[0m
[0m[[0mdebug[0m] [0m	org.apache.spark.sql.execution.CS186UtilsSuite[0m
[0m[[0mdebug[0m] [0m	org.apache.spark.sql.execution.DiskPartitionSuite[0m
[0m[[0mdebug[0m] [0m	org.apache.spark.sql.execution.DiskHashedRelationSuite[0m
